{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11741670-124f-4a46-b4bd-a5ef2f834e9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T02:06:16.449465Z",
     "start_time": "2024-08-01T02:06:12.515077Z"
    },
    "execution": {
     "iopub.execute_input": "2024-10-30T03:26:08.593951Z",
     "iopub.status.busy": "2024-10-30T03:26:08.593430Z",
     "iopub.status.idle": "2024-10-30T03:26:08.599916Z",
     "shell.execute_reply": "2024-10-30T03:26:08.599267Z",
     "shell.execute_reply.started": "2024-10-30T03:26:08.593920Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "import os\n",
    "import math\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import psutil\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "import xarray as xr\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.signal import savgol_filter\n",
    "from matplotlib import gridspec\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import cartopy.crs as ccrs\n",
    "import joypy\n",
    "from osgeo import gdal\n",
    "import matplotlib as mpl\n",
    "from cartopy.mpl.ticker import LatitudeFormatter, LongitudeFormatter\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "981f49ed-4f97-4f58-b4ec-9165bf9e7fdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T03:26:17.382922Z",
     "iopub.status.busy": "2024-10-30T03:26:17.382535Z",
     "iopub.status.idle": "2024-10-30T03:26:17.415356Z",
     "shell.execute_reply": "2024-10-30T03:26:17.414697Z",
     "shell.execute_reply.started": "2024-10-30T03:26:17.382896Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_tif(tif_file):\n",
    "    dataset = gdal.Open(tif_file)\n",
    "    cols = dataset.RasterXSize\n",
    "    rows = dataset.RasterYSize\n",
    "    im_proj = (dataset.GetProjection())\n",
    "    im_Geotrans = (dataset.GetGeoTransform())\n",
    "    im_data = dataset.ReadAsArray(0, 0, cols, rows)\n",
    "    if im_data.ndim == 3:\n",
    "        im_data = np.moveaxis(dataset.ReadAsArray(0, 0, cols, rows), 0, -1)\n",
    "    dataset = None\n",
    "    return im_data, im_Geotrans, im_proj,rows, cols\n",
    "    \n",
    "def array_to_geotiff(array, output_path, geo_transform, projection, band_names=None):\n",
    "    rows, cols, num_bands = array.shape\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    dataset = driver.Create(output_path, cols, rows, num_bands, gdal.GDT_Float32)\n",
    "    \n",
    "    dataset.SetGeoTransform(geo_transform)\n",
    "    dataset.SetProjection(projection)\n",
    "    \n",
    "    for band_num in range(num_bands):\n",
    "        band = dataset.GetRasterBand(band_num + 1)\n",
    "        band.WriteArray(array[:, :, band_num])\n",
    "        band.FlushCache()\n",
    "        \n",
    "        if band_names:\n",
    "            band.SetDescription(band_names[band_num])\n",
    "    \n",
    "    dataset = None\n",
    "    band = None\n",
    "    return\n",
    "\n",
    "def get_corner(image_file):\n",
    "    dataset = gdal.Open(image_file)\n",
    "    geo_transform = dataset.GetGeoTransform()\n",
    "    x_res = geo_transform[1]\n",
    "    y_res = geo_transform[5] \n",
    "    x_min = geo_transform[0]\n",
    "    y_max = geo_transform[3]\n",
    "    x_max = x_min + x_res * dataset.RasterXSize\n",
    "    y_min = y_max + y_res * dataset.RasterYSize\n",
    "    \n",
    "    x_size = dataset.RasterXSize\n",
    "    y_size = dataset.RasterYSize\n",
    "    im_proj = dataset.GetProjection()\n",
    "    return im_proj, x_res, y_res, x_size, y_size, (x_min, y_min, x_max, y_max)\n",
    "\n",
    "class BandInfo:\n",
    "    def __init__(self):\n",
    "        self.centers = None\n",
    "        self.bandwidths = None\n",
    "        self.centers_stdevs = None\n",
    "        self.bandwidth_stdevs = None\n",
    "        self.band_quantity = None\n",
    "        self.band_unit = None\n",
    "\n",
    "def erf_local(x):\n",
    "    sign = 1 if x >= 0 else -1\n",
    "    x = abs(x)\n",
    "    a1 =  0.254829592\n",
    "    a2 = -0.284496736\n",
    "    a3 =  1.421413741\n",
    "    a4 = -1.453152027\n",
    "    a5 =  1.061405429\n",
    "    p  =  0.3275911\n",
    "\n",
    "    t = 1.0/(1.0 + p*x)\n",
    "    y = 1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*math.exp(-x*x)\n",
    "    return sign*y # erf(-x) = -erf(x)\n",
    "\n",
    "try:\n",
    "    from math import erf\n",
    "except:\n",
    "    try:\n",
    "        from scipy.special import erf\n",
    "    except:\n",
    "        erf = erf_local\n",
    "\n",
    "def erfc(z):\n",
    "    '''Complement of the error function.'''\n",
    "    return 1.0 - erf(z)\n",
    "\n",
    "def normal_cdf(x):\n",
    "    '''CDF of the normal distribution.'''\n",
    "    sqrt2 = 1.4142135623730951\n",
    "    return 0.5 * erfc(-x / sqrt2)\n",
    "\n",
    "def normal_integral(a, b):\n",
    "    '''Integral of the normal distribution from a to b.'''\n",
    "    return normal_cdf(b) - normal_cdf(a)\n",
    "\n",
    "def ranges_overlap(R1, R2):\n",
    "    '''Returns True if there is overlap between ranges of pairs R1 and R2.'''\n",
    "    if (R1[0] < R2[0] and R1[1] < R2[0]) or \\\n",
    "       (R1[0] > R2[1] and R1[1] > R2[1]):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def overlap(R1, R2):\n",
    "    '''Returns (min, max) of overlap between the ranges of pairs R1 and R2.'''\n",
    "    return (max(R1[0], R2[0]), min(R1[1], R2[1]))\n",
    "\n",
    "def normal(mean, stdev, x):\n",
    "    sqrt_2pi = 2.5066282746310002\n",
    "    return math.exp(-((x - mean) / stdev)**2 / 2.0) / (sqrt_2pi * stdev)\n",
    "\n",
    "def build_fwhm(centers):\n",
    "    '''Returns FWHM list, assuming FWHM is midway between adjacent bands.\n",
    "    '''\n",
    "    fwhm = [0] * len(centers)\n",
    "    fwhm[0] = centers[1] - centers[0]\n",
    "    fwhm[-1] = centers[-1] - centers[-2]\n",
    "    for i in range(1, len(centers) - 1):\n",
    "        fwhm[i] = (centers[i + 1] - centers[i - 1]) / 2.0\n",
    "    return fwhm\n",
    "\n",
    "def create_resampling_matrix(centers1, fwhm1, centers2, fwhm2):\n",
    "    logger = logging.getLogger('spectral')\n",
    "\n",
    "    sqrt_8log2 = 2.3548200450309493\n",
    "\n",
    "    N1 = len(centers1)\n",
    "    N2 = len(centers2)\n",
    "    bounds1 = [[centers1[i] - fwhm1[i] / 2.0, centers1[i] + fwhm1[i] /\n",
    "                2.0] for i in range(N1)]\n",
    "    bounds2 = [[centers2[i] - fwhm2[i] / 2.0, centers2[i] + fwhm2[i] /\n",
    "                2.0] for i in range(N2)]\n",
    "\n",
    "    M = np.zeros([N2, N1])\n",
    "\n",
    "    jStart = 0\n",
    "    nan = float('nan')\n",
    "    for i in range(N2):\n",
    "        stdev = fwhm2[i] / sqrt_8log2\n",
    "        j = jStart\n",
    "\n",
    "        # Find the first original band that overlaps the new band\n",
    "        while j < N1 and bounds1[j][1] < bounds2[i][0]:\n",
    "            j += 1\n",
    "\n",
    "        if j == N1:\n",
    "            logger.info(('No overlap for target band %d (%f / %f)' % (\n",
    "                i, centers2[i], fwhm2[i])))\n",
    "            M[i, 0] = nan\n",
    "            continue\n",
    "\n",
    "        matches = []\n",
    "\n",
    "        # Get indices for all original bands that overlap the new band\n",
    "        while j < N1 and bounds1[j][0] < bounds2[i][1]:\n",
    "            if ranges_overlap(bounds1[j], bounds2[i]):\n",
    "                matches.append(j)\n",
    "            j += 1\n",
    "\n",
    "        # Put NaN in first element of any row that doesn't produce a band in\n",
    "        # the new schema.\n",
    "        if len(matches) == 0:\n",
    "            logger.info('No overlap for target band %d (%f / %f)',\n",
    "                         i, centers2[i], fwhm2[i])\n",
    "            M[i, 0] = nan\n",
    "            continue\n",
    "\n",
    "        # Determine the weights for the original bands that overlap the new\n",
    "        # band. There may be multiple bands that overlap or even just a single\n",
    "        # band that only partially overlaps.  Weights are normoalized so either\n",
    "        # case can be handled.\n",
    "\n",
    "        overlaps = [overlap(bounds1[k], bounds2[i]) for k in matches]\n",
    "        contribs = np.zeros(len(matches))\n",
    "        A = 0.\n",
    "        for k in range(len(matches)):\n",
    "            #endNorms = [normal(centers2[i], stdev, x) for x in overlaps[k]]\n",
    "            #dA = (overlaps[k][1] - overlaps[k][0]) * sum(endNorms) / 2.0\n",
    "            (a, b) = [(x - centers2[i]) / stdev for x in overlaps[k]]\n",
    "            dA = normal_integral(a, b)\n",
    "            contribs[k] = dA\n",
    "            A += dA\n",
    "        contribs = contribs / A\n",
    "        for k in range(len(matches)):\n",
    "            M[i, matches[k]] = contribs[k]\n",
    "    return M\n",
    "\n",
    "class BandResampler:\n",
    "    def __init__(self, centers1, centers2, fwhm1=None, fwhm2=None):\n",
    "        if isinstance(centers1, BandInfo):\n",
    "            fwhm1 = centers1.bandwidths\n",
    "            centers1 = centers1.centers\n",
    "        if isinstance(centers2, BandInfo):\n",
    "            fwhm2 = centers2.bandwidths\n",
    "            centers2 = centers2.centers\n",
    "        if fwhm1 is None:\n",
    "            fwhm1 = build_fwhm(centers1)\n",
    "        if fwhm2 is None:\n",
    "            fwhm2 = build_fwhm(centers2)\n",
    "        self.matrix = create_resampling_matrix(\n",
    "            centers1, fwhm1, centers2, fwhm2)\n",
    "\n",
    "    def __call__(self, spectrum):\n",
    "        return np.dot(self.matrix, spectrum)\n",
    "\n",
    "def do_resample(spectra, source_wvl, source_fwhm):\n",
    "    centers1 = source_wvl\n",
    "    centers2 = np.arange(580,930,1)\n",
    "    fwhm1 = source_fwhm\n",
    "    fwhm2 = build_fwhm(centers2)\n",
    "    resampler = BandResampler(centers1, centers2, fwhm1, fwhm2)\n",
    "    resampled_spectra = resampler(spectra)\n",
    "    return resampled_spectra\n",
    "\n",
    "def compute_weighted_reflectance(response_curve_wl, hyper_wl, hyper_data, response_curve, hyper_fwhm):\n",
    "    interp_reflectance = do_resample(hyper_data, hyper_wl, hyper_fwhm)    \n",
    "    numerator = np.trapz(interp_reflectance * response_curve, response_curve_wl)\n",
    "    denominator = np.trapz(response_curve, response_curve_wl)\n",
    "    weighted_reflectance = numerator/denominator\n",
    "    return weighted_reflectance\n",
    "\n",
    "def run_parallel(image_chunk, response_curve_wl, response_curve_data, wvl, fwhm):\n",
    "    results = np.zeros(shape = (image_chunk.shape[0], image_chunk.shape[1],2))\n",
    "    for i in range(image_chunk.shape[0]):\n",
    "        for j in range(image_chunk.shape[1]):\n",
    "            spectra = image_chunk[i, j, :]\n",
    "            spectra = np.nan_to_num(spectra, nan=0)\n",
    "    \n",
    "            simulated_spectra = []\n",
    "            for kk in [7,11]:\n",
    "                response_curve = response_curve_data[kk,:][200:550]\n",
    "                refl = compute_weighted_reflectance(response_curve_wl, wvl, spectra, response_curve, fwhm)\n",
    "                simulated_spectra.append(refl)\n",
    "            results[i,j,:] = simulated_spectra\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e85417e-8f74-4aaa-9a65-a08bd7cca208",
   "metadata": {},
   "source": [
    "### 1. convolved prisma imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ee6ce2-9ecd-4599-9f95-061c5c82b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "RSR = \"/Volumes/ChenLab/Fujiang/0_PhD_dissertation_data/12_RTM_estimation_through_given_LAI/1_LAI_estimation/2_MODIS_convolved_PRISMA_imagery/terra_modis_RSR.nc\"\n",
    "spectral_response = xr.open_dataset(RSR)\n",
    "# exported_bands = spectral_response[\"bands\"].data[1:13]\n",
    "exported_bands = spectral_response[\"bands\"].data[np.array([7,11])]\n",
    "\n",
    "response_curve_wl = spectral_response[\"wavelength\"].data[200:550]\n",
    "response_curve_data = spectral_response[\"RSR\"].data\n",
    "\n",
    "############################################################################\n",
    "data_path = \"/Volumes/ChenLab/Fujiang/0_PhD_dissertation_data/4_Extract_training_data/9_PRISMA_imagery_smoothed_tif/\"\n",
    "wvl_path = \"/Volumes/ChenLab/Fujiang/0_PhD_dissertation_data/2_PRISMA_L2D/2_PRISMA_L2D_tif_2020_2023/\"\n",
    "out_path = \"/Volumes/ChenLab/Fujiang/0_PhD_dissertation_data/12_RTM_estimation_through_given_LAI/1_LAI_estimation/2_MODIS_convolved_PRISMA_imagery/\"\n",
    "\n",
    "folders = ['D01_BART','D01_HARV','D02_SCBI','D03_OSBS','D07_MLBS','D07_ORNL','D08_TALL',\n",
    "           'D10_CPER','D13_MOAB','D14_JORN','D14_SRER','D16_WREF','D19_BONA','D19_HEAL']\n",
    "\n",
    "for folder in folders[0:1]:\n",
    "    os.makedirs(f\"{out_path}/{folder}\", exist_ok=True)\n",
    "    imagery_path = f\"{data_path}{folder}\"\n",
    "    wvl_folder = f\"{wvl_path}{folder}\"\n",
    "    output_path = f\"{out_path}{folder}\"\n",
    "    \n",
    "    file_name = os.listdir(imagery_path)\n",
    "    file_name = [x for x in file_name if \"_FULL.tif\" in x and \"._\" not in x and \".aux.xml\" not in x]\n",
    "\n",
    "    idx = 1\n",
    "    for file in file_name[0:1]:\n",
    "        print(f\"{folder} -- {idx}/{len(file_name)} -- {file}\")\n",
    "        \n",
    "        wvl_file = f\"{wvl_folder}/{file.split('.')[0]}.wvl\"\n",
    "        df = pd.read_csv(wvl_file,delimiter=\" \")\n",
    "        im_data, im_Geotrans, im_proj,rows, cols = read_tif(f\"{imagery_path}/{file}\")\n",
    "        \n",
    "        wvl = df[\"wl\"].values[20:60]\n",
    "        fwhm = df[\"fwhm\"].values[20:60]\n",
    "        im_data = im_data[:,:,20:60]\n",
    "        \n",
    "        chunk_size = 50\n",
    "        image_chunks = []\n",
    "        for i in range(0, im_data.shape[0], chunk_size):\n",
    "                for j in range(0, im_data.shape[1], chunk_size):\n",
    "                    chunk = im_data[i:i + chunk_size, j:j + chunk_size]\n",
    "                    image_chunks.append(chunk)\n",
    "                    \n",
    "        num_processes = psutil.cpu_count(logical=False)\n",
    "        chunk_results = Parallel(n_jobs=num_processes)(delayed(run_parallel)(image_chunk, response_curve_wl, response_curve_data, wvl, fwhm) for image_chunk in tqdm(image_chunks,desc=\"Processing Chunks\"))\n",
    "\n",
    "        convolved_imagery = np.zeros(shape = (im_data.shape[0], im_data.shape[1], 2))\n",
    "        chunk_index = 0\n",
    "        for i in range(0, convolved_imagery.shape[0], chunk_size):\n",
    "            for j in range(0, convolved_imagery.shape[1], chunk_size):\n",
    "                convolved_imagery[i:i + chunk_size, j:j + chunk_size,:] = chunk_results[chunk_index]\n",
    "                chunk_index = chunk_index+1\n",
    "                \n",
    "        out_tif = f\"{output_path}/{file[:-4]}_convolved.tif\"\n",
    "        band_names = [f\"{x} nm\" for x in exported_bands]\n",
    "        array_to_geotiff(convolved_imagery, out_tif, im_Geotrans, im_proj, band_names=band_names)\n",
    "        idx = idx +1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c098f900-9881-48df-961b-e6ee2a81f024",
   "metadata": {},
   "source": [
    "### 2. calculate PRISMA VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf9283a8-4bc6-41af-a831-6a037027e336",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T03:26:21.330302Z",
     "iopub.status.busy": "2024-10-30T03:26:21.329897Z",
     "iopub.status.idle": "2024-10-30T03:27:50.336657Z",
     "shell.execute_reply": "2024-10-30T03:27:50.334968Z",
     "shell.execute_reply.started": "2024-10-30T03:26:21.330277Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"/Volumes/ChenLab/Fujiang/0_Seasonal_PRISMA_traits/12_RTM_estimation_through_given_LAI/1_LAI_estimation/2_MODIS_convolved_PRISMA_imagery/NBAR_refl/\"\n",
    "out_path = \"/Volumes/ChenLab/Fujiang/0_Seasonal_PRISMA_traits/12_RTM_estimation_through_given_LAI/1_LAI_estimation/3_NDVI_NIRv/NBAR_refl/\"\n",
    "\n",
    "folders = ['D01_BART','D01_HARV','D02_SCBI','D03_OSBS','D07_MLBS','D07_ORNL','D08_TALL',\n",
    "           'D10_CPER','D13_MOAB','D14_JORN','D14_SRER','D16_WREF','D19_BONA','D19_HEAL']\n",
    "\n",
    "for folder in folders:\n",
    "    os.makedirs(f\"{out_path}/{folder}\", exist_ok=True)\n",
    "    imagery_path = f\"{data_path}{folder}\"\n",
    "    output_path = f\"{out_path}{folder}\"\n",
    "    \n",
    "    file_name = os.listdir(imagery_path)\n",
    "    file_name = [x for x in file_name if \"_FULL_NBAR_convolved.tif\" in x and \"._\" not in x and \".aux.xml\" not in x]\n",
    "    \n",
    "    for file in file_name:\n",
    "        im_data, im_Geotrans, im_proj,rows, cols = read_tif(f\"{imagery_path}/{file}\")\n",
    "        red = im_data[:,:,0]\n",
    "        nir = im_data[:,:,1]\n",
    "        ndvi  = (nir - red)/ (nir + red)\n",
    "        nirv = ndvi*nir\n",
    "        data_array = np.stack([ndvi, nirv], axis = -1)\n",
    "        out_tif = f\"{output_path}/{file[:-4]}_VI.tif\"\n",
    "        array_to_geotiff(data_array, out_tif, im_Geotrans, im_proj, band_names=[\"NDVI\", \"NIRV\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de106ae8-ca3c-4b93-995f-7eb296502c50",
   "metadata": {},
   "source": [
    "### 3. clipped lulc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fb1c414-c154-4018-921e-510d7e048f95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T03:28:56.997941Z",
     "iopub.status.busy": "2024-10-30T03:28:56.997303Z",
     "iopub.status.idle": "2024-10-30T03:29:30.153055Z",
     "shell.execute_reply": "2024-10-30T03:29:30.152694Z",
     "shell.execute_reply.started": "2024-10-30T03:28:56.997876Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"/Volumes/ChenLab/Fujiang/0_Seasonal_PRISMA_traits/12_RTM_estimation_through_given_LAI/1_LAI_estimation/3_NDVI_NIRv/NBAR_refl/\"\n",
    "out_path = \"/Volumes/ChenLab/Fujiang/0_Seasonal_PRISMA_traits/12_RTM_estimation_through_given_LAI/1_LAI_estimation/4_clipped_lulc/NBAR_refl/\"\n",
    "lulc_path = \"/Volumes/ChenLab/Fujiang/0_Seasonal_PRISMA_traits/3_GLC_FCS30D_Land_cover_data_US/4_land_cover_NEON_sites/\"\n",
    "\n",
    "folders = ['D01_BART','D01_HARV','D02_SCBI','D03_OSBS','D07_MLBS','D07_ORNL','D08_TALL',\n",
    "           'D10_CPER','D13_MOAB','D14_JORN','D14_SRER','D16_WREF','D19_BONA','D19_HEAL']\n",
    "\n",
    "for folder in folders:\n",
    "    os.makedirs(f\"{out_path}/{folder}\", exist_ok=True)\n",
    "    imagery_path = f\"{data_path}{folder}\"\n",
    "    output_path = f\"{out_path}{folder}\"\n",
    "    lulc_folder = f\"{lulc_path}{folder}\"\n",
    "    \n",
    "    file_name = os.listdir(imagery_path)\n",
    "    file_name = [x for x in file_name if \"_FULL_NBAR_convolved_VI.tif\" in x and \"._\" not in x and \".aux.xml\" not in x]\n",
    "    \n",
    "    for file in file_name:\n",
    "        vi_tif = f\"{imagery_path}/{file}\"\n",
    "        \n",
    "        year = file.split(\"_\")[3][0:4]\n",
    "        if year == \"2023\":\n",
    "            year =\"2022\"\n",
    "        lulc_file = f\"{lulc_folder}/{folder}_{year}_land_cover.tif\"\n",
    "        out_lulc = f\"{output_path}/{file[:-4]}_lulc.tif\"\n",
    "\n",
    "        input_ds = gdal.Open(lulc_file)\n",
    "        proj, x_res, y_res, x_size, y_size, bounds = get_corner(vi_tif)\n",
    "        gdal.Warp(out_lulc, input_ds, xRes=x_res, yRes=abs(y_res),dstSRS=proj, outputBounds=bounds, \n",
    "                  width=x_size, height=y_size, resampleAlg=gdal.GRA_NearestNeighbour)\n",
    "        input_ds = None\n",
    "        out_lulc = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07209c1-f27a-4509-9f48-30544b0a9152",
   "metadata": {},
   "source": [
    "### 4. merged with lulc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec305697-5212-4a09-8436-d657208e3314",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T03:30:42.943555Z",
     "iopub.status.busy": "2024-10-30T03:30:42.943071Z",
     "iopub.status.idle": "2024-10-30T03:32:52.200620Z",
     "shell.execute_reply": "2024-10-30T03:32:52.199541Z",
     "shell.execute_reply.started": "2024-10-30T03:30:42.943492Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"/Volumes/ChenLab/Fujiang/0_Seasonal_PRISMA_traits/12_RTM_estimation_through_given_LAI/1_LAI_estimation/3_NDVI_NIRv/NBAR_refl/\"\n",
    "lulc_path = \"/Volumes/ChenLab/Fujiang/0_Seasonal_PRISMA_traits/12_RTM_estimation_through_given_LAI/1_LAI_estimation/4_clipped_lulc/NBAR_refl/\"\n",
    "out_path = \"/Volumes/ChenLab/Fujiang/0_Seasonal_PRISMA_traits/12_RTM_estimation_through_given_LAI/1_LAI_estimation/5_merged_with_lulc/NBAR_refl/\"\n",
    "\n",
    "folders = ['D01_BART','D01_HARV','D02_SCBI','D03_OSBS','D07_MLBS','D07_ORNL','D08_TALL',\n",
    "           'D10_CPER','D13_MOAB','D14_JORN','D14_SRER','D16_WREF','D19_BONA','D19_HEAL']\n",
    "\n",
    "for folder in folders:\n",
    "    os.makedirs(f\"{out_path}/{folder}\", exist_ok=True)\n",
    "    imagery_path = f\"{data_path}{folder}\"\n",
    "    output_path = f\"{out_path}{folder}\"\n",
    "    lulc_folder = f\"{lulc_path}{folder}\"\n",
    "    \n",
    "    file_name = os.listdir(imagery_path)\n",
    "    file_name = [x for x in file_name if \"_FULL_NBAR_convolved_VI.tif\" in x and \"._\" not in x and \".aux.xml\" not in x]\n",
    "    \n",
    "    for file in file_name:\n",
    "        vi_tif = f\"{imagery_path}/{file}\"\n",
    "        lulc_file = f\"{lulc_folder}/{file[:-4]}_lulc.tif\"\n",
    "        \n",
    "        im_data, im_Geotrans, im_proj,rows, cols = read_tif(vi_tif)\n",
    "        lc_data, lc_Geotrans, im_proj,rows, cols = read_tif(lulc_file)\n",
    "        lc_data = lc_data[:,:,np.newaxis]\n",
    "\n",
    "        im_data = np.concatenate((im_data, lc_data), axis=2)\n",
    "        out_tif = f\"{output_path}/{file}\"\n",
    "        array_to_geotiff(im_data, out_tif, im_Geotrans, im_proj, band_names=[\"NDVI\", \"NIRV\",\"LULC\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc08de3-20d6-49bc-a79c-5b5bd5a6646b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T02:35:36.762427Z",
     "iopub.status.busy": "2024-10-02T02:35:36.761173Z",
     "iopub.status.idle": "2024-10-02T02:35:36.773379Z",
     "shell.execute_reply": "2024-10-02T02:35:36.771886Z",
     "shell.execute_reply.started": "2024-10-02T02:35:36.762319Z"
    }
   },
   "source": [
    "### 5. convert lulc to pft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eaf45a6-16b7-4e2e-acad-dc43c9ecb985",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T03:33:16.911606Z",
     "iopub.status.busy": "2024-10-30T03:33:16.911077Z",
     "iopub.status.idle": "2024-10-30T03:33:16.919498Z",
     "shell.execute_reply": "2024-10-30T03:33:16.918529Z",
     "shell.execute_reply.started": "2024-10-30T03:33:16.911554Z"
    }
   },
   "outputs": [],
   "source": [
    "def transfer_lulc_pft(array):\n",
    "    # land_cover_type = {10: \"Rainfed cropland\",11: \"Herbaceous cover cropland\",12: \"Tree or shrub cover (Orchard) cropland\",\n",
    "    #                    20: \"Irrigated cropland\",51: \"Open evergreen broadleaved forest\",52: \"Closed evergreen broadleaved forest\",\n",
    "    #                    61: \"Open deciduous broadleaved forest\",62: \"Closed deciduous broadleaved forest\",71: \"Open evergreen needle-leaved forest\",\n",
    "    #                    72: \"Closed evergreen needle-leaved forest\",81: \"Open deciduous needle-leaved forest\",82: \"Closed deciduous needle-leaved forest\",\n",
    "    #                    91: \"Open mixed leaf forest (broadleaved and needle-leaved)\",92: \"Closed mixed leaf forest (broadleaved and needle-leaved)\", \n",
    "    #                    120: \"Shrubland\",121: \"Evergreen shrubland\",122: \"Deciduous shrubland\",130: \"Grassland\",140: \"Lichens and mosses\",\n",
    "    #                    150: \"Sparse vegetation\",152: \"Sparse shrubland\",153: \"Sparse herbaceous\",181: \"Swamp\",182: \"Marsh\",183: \"Flooded flat\",\n",
    "    #                    184: \"Saline\",185: \"Mangrove\",186: \"Salt marsh\",187: \"Tidal flat\",190: \"Impervious surfaces\",200: \"Bare areas\",\n",
    "    #                    201: \"Consolidated bare areas\",202: \"Unconsolidated bare areas\",210: \"Water body\",220: \"Permanent ice and snow\",\n",
    "    #                    0: \"Filled value\",250: \"Filled value\"}\n",
    "    \n",
    "    #CPR: lulc = [10, 11, 12, 20] --> 100\n",
    "    #EBF: lulc = [51, 52] --> 200\n",
    "    #DBF: lulc = [61, 62] --> 300\n",
    "    #ENF: lulc = [71, 72] --> 400\n",
    "    #DNF: lulc = [81, 82] --> 500\n",
    "    #MF: lulc = [91, 92] --> 600\n",
    "    #SHR: lulc = [120, 121, 122] --> 700\n",
    "    #GRA: lulc = [130] --> 800\n",
    "    array = array.astype(int)\n",
    "    pft = np.zeros(array.shape)\n",
    "    pft[np.isin(array, [10, 11, 12, 20])] = 100\n",
    "    pft[np.isin(array, [51, 52])] = 200\n",
    "    pft[np.isin(array, [61, 62])] = 300\n",
    "    pft[np.isin(array, [71, 72])] = 400\n",
    "    pft[np.isin(array, [81, 82])] = 500\n",
    "    pft[np.isin(array, [91, 92])] = 600\n",
    "    pft[np.isin(array, [120, 121, 122])] = 700\n",
    "    pft[np.isin(array, [130])] = 800\n",
    "    return pft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7aec5b6-6f00-498d-8c07-c6ab24679e3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T03:33:20.909985Z",
     "iopub.status.busy": "2024-10-30T03:33:20.909587Z",
     "iopub.status.idle": "2024-10-30T03:35:39.044928Z",
     "shell.execute_reply": "2024-10-30T03:35:39.043967Z",
     "shell.execute_reply.started": "2024-10-30T03:33:20.909958Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"/Volumes/ChenLab/Fujiang/0_Seasonal_PRISMA_traits/12_RTM_estimation_through_given_LAI/1_LAI_estimation/5_merged_with_lulc/NBAR_refl/\"\n",
    "out_path = \"/Volumes/ChenLab/Fujiang/0_Seasonal_PRISMA_traits/12_RTM_estimation_through_given_LAI/1_LAI_estimation/6_convert_lulc_pft/NBAR_refl/\"\n",
    "\n",
    "folders = ['D01_BART','D01_HARV','D02_SCBI','D03_OSBS','D07_MLBS','D07_ORNL','D08_TALL',\n",
    "           'D10_CPER','D13_MOAB','D14_JORN','D14_SRER','D16_WREF','D19_BONA','D19_HEAL']\n",
    "\n",
    "for folder in folders:\n",
    "    os.makedirs(f\"{out_path}/{folder}\", exist_ok=True)\n",
    "    imagery_path = f\"{data_path}{folder}\"\n",
    "    output_path = f\"{out_path}{folder}\"\n",
    "    \n",
    "    file_name = os.listdir(imagery_path)\n",
    "    file_name = [x for x in file_name if \"_FULL_NBAR_convolved_VI.tif\" in x and \"._\" not in x and \".aux.xml\" not in x]\n",
    "    for file in file_name:\n",
    "        im_data, im_Geotrans, im_proj,rows, cols = read_tif(f\"{imagery_path}/{file}\")\n",
    "        pft = transfer_lulc_pft(im_data[:,:,-1])\n",
    "        pft = pft[:, :, np.newaxis]\n",
    "        data_array = im_data[:,:,:-1]        \n",
    "        im_data = np.concatenate((data_array, pft), axis=2)\n",
    "        \n",
    "        out_tif = f\"{output_path}/{file}\"\n",
    "        array_to_geotiff(im_data, out_tif, im_Geotrans, im_proj, band_names=[\"NDVI\", \"NIRV\",\"PFT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e61b8c-9fba-4828-8ed4-bc295fa8e8d0",
   "metadata": {},
   "source": [
    "### 6. calculate PRISMA LAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "9e6fe000-eeba-4cef-a842-8e0bc02006f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T05:57:20.164556Z",
     "iopub.status.busy": "2024-10-02T05:57:20.163756Z",
     "iopub.status.idle": "2024-10-02T05:57:20.180447Z",
     "shell.execute_reply": "2024-10-02T05:57:20.179219Z",
     "shell.execute_reply.started": "2024-10-02T05:57:20.164481Z"
    }
   },
   "outputs": [],
   "source": [
    "def exponential_model(x, a, b):\n",
    "    return a * np.exp(b * x)\n",
    "def linear_model(x, a, b):\n",
    "    return a * x +b\n",
    "def estimate_LAI_parallel(image_chunk, model, site):\n",
    "    pft_map = {100:\"CPR\",200:\"EBF\", 300:\"DBF\", 400:\"ENF\", 500:\"DNF\", 600:\"MF\", 700:\"SHR\", 800:\"GRA\", 0: \"all\"}\n",
    "    results = np.zeros(shape = (image_chunk.shape[0], image_chunk.shape[1]))\n",
    "    for i in range(image_chunk.shape[0]):\n",
    "            for j in range(image_chunk.shape[1]):\n",
    "                points = image_chunk[i, j, :]\n",
    "                ndvi, nirv, pft = points[0],points[1],points[2]\n",
    "                \n",
    "                ndvi = np.clip(ndvi, -2, 2)\n",
    "                nirv = np.clip(nirv, -2, 2)\n",
    "                \n",
    "                PFT = pft_map[pft]\n",
    "                \n",
    "                temp = model[model[\"site\"] == site]\n",
    "                model_pft = temp[\"PFT\"].unique()\n",
    "                if PFT not in model_pft:\n",
    "                    ml = temp[temp[\"PFT\"] == \"all\"]\n",
    "                else:\n",
    "                    ml = temp[temp[\"PFT\"] == PFT]\n",
    "\n",
    "                max_ml = ml.loc[ml['R2'].idxmax()]\n",
    "                a, b = max_ml[\"a\"],max_ml[\"b\"]\n",
    "                if max_ml[\"x\"] == \"NDVI\":\n",
    "                    LAI = exponential_model(ndvi, a, b)\n",
    "                else:\n",
    "                    LAI = linear_model(nirv, a, b)\n",
    "                results[i, j] = LAI\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "8b111e0d-4c83-43d1-a12b-d704f1737df8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T05:39:18.651610Z",
     "iopub.status.busy": "2024-10-02T05:39:18.650841Z",
     "iopub.status.idle": "2024-10-02T05:39:19.896398Z",
     "shell.execute_reply": "2024-10-02T05:39:19.896072Z",
     "shell.execute_reply.started": "2024-10-02T05:39:18.651564Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"/Volumes/ChenLab/Fujiang/0_PhD_dissertation_data/12_RTM_estimation_through_given_LAI/1_LAI_estimation/6_convert_lulc_pft/\"\n",
    "out_path = \"/Volumes/ChenLab/Fujiang/0_PhD_dissertation_data/12_RTM_estimation_through_given_LAI/1_LAI_estimation/7_estimated_LAI/\"\n",
    "model_path = \"/Volumes/ChenLab/Fujiang/0_PhD_dissertation_data/12_RTM_estimation_through_given_LAI/1_LAI_estimation/1_original_data/8_extract_VI_LAI_to_points/\"\n",
    "model = pd.read_csv(f\"{model_path}2_saved_models.csv\")\n",
    "\n",
    "folders = ['D01_BART','D01_HARV','D02_SCBI','D03_OSBS','D07_MLBS','D07_ORNL','D08_TALL',\n",
    "           'D10_CPER','D13_MOAB','D14_JORN','D14_SRER','D16_WREF','D19_BONA','D19_HEAL']\n",
    "\n",
    "for folder in folders[3:4]:\n",
    "    os.makedirs(f\"{out_path}/{folder}\", exist_ok=True)\n",
    "    imagery_path = f\"{data_path}{folder}\"\n",
    "    output_path = f\"{out_path}{folder}\"\n",
    "    \n",
    "    file_name = os.listdir(imagery_path)\n",
    "    file_name = [x for x in file_name if \"_FULL_convolved_VI.tif\" in x and \"._\" not in x and \".aux.xml\" not in x]\n",
    "\n",
    "    site = folder[-4:]\n",
    "    for file in file_name:\n",
    "        im_data, im_Geotrans, im_proj,rows, cols = read_tif(f\"{imagery_path}/{file}\")\n",
    "        im_data = np.where(np.isnan(im_data), 0, im_data)\n",
    "        \n",
    "        chunk_size = 50\n",
    "        image_chunks = []\n",
    "        for i in range(0, im_data.shape[0], chunk_size):\n",
    "                for j in range(0, im_data.shape[1], chunk_size):\n",
    "                    chunk = im_data[i:i + chunk_size, j:j + chunk_size]\n",
    "                    image_chunks.append(chunk)\n",
    "\n",
    "        num_processes = psutil.cpu_count(logical=False)\n",
    "        chunk_results = Parallel(n_jobs=num_processes)(delayed(estimate_LAI_parallel)(image_chunk, model, site) for image_chunk in tqdm(image_chunks,desc=\"Processing Chunks\"))\n",
    "        \n",
    "        result_imagery = np.zeros(shape = (im_data.shape[0], im_data.shape[1]))\n",
    "        chunk_index = 0\n",
    "        for i in range(0, result_imagery.shape[0], chunk_size):\n",
    "            for j in range(0, result_imagery.shape[1], chunk_size):\n",
    "                result_imagery[i:i + chunk_size, j:j + chunk_size] = chunk_results[chunk_index]\n",
    "                chunk_index = chunk_index+1\n",
    "                \n",
    "        result_imagery = result_imagery[:, :, np.newaxis]\n",
    "        out_tif = f\"{output_path}/{file[:-17]}_LAI.tif\"\n",
    "        array_to_geotiff(result_imagery, out_tif, im_Geotrans, im_proj, band_names=[\"LAI\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "362.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
