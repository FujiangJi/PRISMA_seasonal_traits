{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5322b9f6-96f3-48dc-9f0d-42827604c490",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T02:48:03.515093Z",
     "start_time": "2024-05-22T02:48:03.509130Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-01T22:10:06.754455Z",
     "iopub.status.busy": "2024-02-01T22:10:06.753529Z",
     "iopub.status.idle": "2024-02-01T22:10:06.762790Z",
     "shell.execute_reply": "2024-02-01T22:10:06.761033Z",
     "shell.execute_reply.started": "2024-02-01T22:10:06.754362Z"
    }
   },
   "outputs": [],
   "source": [
    "import cartopy.io.shapereader as shpreader\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from osgeo import gdal,ogr, osr\n",
    "import xarray\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77701c9e",
   "metadata": {},
   "source": [
    "## 1. Daymet forcing data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a71392c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T23:32:25.642932Z",
     "start_time": "2024-05-16T23:32:25.632285Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_tif(array, x, y, out_path, date, var, proj,shapefile):\n",
    "    rows, cols = array.shape\n",
    "    xmin, pixel_size, ymax = x.min(), x[1]-x[0], y.max()\n",
    "\n",
    "    geotransform = (xmin, pixel_size, 0, ymax, 0, -pixel_size)\n",
    "\n",
    "    output_tif_file = f\"{out_path}{var}/{date}_{var}.tif\"\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "\n",
    "    dataset = driver.Create(output_tif_file, cols, rows, 1, gdal.GDT_Float32)\n",
    "\n",
    "    projection = osr.SpatialReference()\n",
    "    projection.SetProjCS(proj.grid_mapping_name)\n",
    "    projection.SetLCC(proj.standard_parallel[0], proj.standard_parallel[1], proj.latitude_of_projection_origin, proj.longitude_of_central_meridian,proj.false_easting, proj.false_northing)\n",
    "    projection.SetGeogCS(\"WGS 84\",\n",
    "                         \"WGS 84\",\n",
    "                         \"WGS 84\",\n",
    "                         proj.semi_major_axis,\n",
    "                         proj.inverse_flattening)\n",
    "\n",
    "    dataset.SetGeoTransform(geotransform)\n",
    "    dataset.SetProjection(projection.ExportToWkt())\n",
    "    dataset.GetRasterBand(1).WriteArray(array)\n",
    "    dataset = None\n",
    "\n",
    "    input_ds = gdal.Open(output_tif_file)\n",
    "    output_ds = gdal.Warp(output_tif_file, input_ds, cutlineDSName=shapefile, cropToCutline=True, dstNodata=0)\n",
    "\n",
    "    input_ds = None\n",
    "    output_ds = None\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf30d46c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T18:19:36.948527Z",
     "start_time": "2024-05-16T23:33:19.897477Z"
    }
   },
   "outputs": [],
   "source": [
    "variables = [\"dayl\",\"prcp\",\"srad\",\"tmax\",\"tmin\",\"vp\"]\n",
    "years = [\"2020\",\"2021\",\"2022\",\"2023\"]\n",
    "\n",
    "data_path = \"/Volumes/ChenLab/Fujiang/0_PhD_dissertation_data/5_Forcing_data/1_original_data/\"\n",
    "out_path = \"/Volumes/ChenLab/Fujiang/0_PhD_dissertation_data/5_Forcing_data/2_clipped_us_extent/\"\n",
    "shapefile = \"/Volumes/ChenLab/Fujiang/0_PhD_dissertation_data/5_Forcing_data/2_clipped_us_extent/0_us_shapefile/us_mainland.shp\"\n",
    "\n",
    "for var in variables:\n",
    "    os.makedirs(f\"{out_path}{var}\", exist_ok=True)\n",
    "    for yrs in years:\n",
    "        file_name = f\"{data_path}daymet_v4_daily_na_{var}_{yrs}.nc\"\n",
    "        file = xarray.open_dataset(file_name)\n",
    "        data = file[var]\n",
    "        \n",
    "        x = file[\"x\"].values\n",
    "        y = file[\"y\"].values\n",
    "        proj = file[\"lambert_conformal_conic\"]\n",
    "        for i in range(data.shape[0]):\n",
    "            data_array = data[i,:,:]\n",
    "            date = str(data_array[\"time\"].values.astype('datetime64[D]'))\n",
    "            print(var, date)\n",
    "            tif_array = data_array.values\n",
    "            to_tif(tif_array, x, y, out_path, date, var, proj,shapefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32735d6b",
   "metadata": {},
   "source": [
    "## 2. Convert projection to geographic coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d30dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Volumes/ChenLab/Fujiang/0_PhD_dissertation_data/5_Forcing_data/2_clipped_us_extent/\"\n",
    "out_path = \"/Volumes/ChenLab/Fujiang/0_PhD_dissertation_data/5_Forcing_data/3_clipped_forcing_WGS84/\"\n",
    "\n",
    "variables = [\"dayl\",\"prcp\",\"srad\",\"tmax\",\"tmin\",\"vp\"]\n",
    "\n",
    "for var in  variables:\n",
    "    file_name = os.listdir(f\"{data_path}{var}\")\n",
    "    file_name = [x for x in file_name if \".tif\" in x and \".aux.xml\" not in x and \"._\" not in x]\n",
    "    for file in file_name:\n",
    "        input_file = f\"{data_path}{var}/{file}\"\n",
    "        output_file = f\"{out_path}{var}/{file}\"\n",
    "        dataset = gdal.Open(input_file)\n",
    "        print(var,datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),file,\"finished\")\n",
    "        gdal.Warp(output_file, dataset, dstSRS='EPSG:4326')\n",
    "        dataset = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9b8b22",
   "metadata": {},
   "source": [
    "## 3. clip using NEON site extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1934be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T06:12:32.853638Z",
     "start_time": "2024-05-22T02:49:33.394084Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_tif(tif_file):\n",
    "    dataset = gdal.Open(tif_file)\n",
    "    cols = dataset.RasterXSize\n",
    "    rows = dataset.RasterYSize\n",
    "    im_proj = (dataset.GetProjection())\n",
    "    im_Geotrans = (dataset.GetGeoTransform())\n",
    "    im_data = np.moveaxis(dataset.ReadAsArray(0, 0, cols, rows), 0, -1)\n",
    "    return im_data, im_Geotrans, im_proj,rows, cols\n",
    "\n",
    "prisma_path = \"/Volumes/ChenLab/Fujiang/0_PhD_dissertation_data/2_PRISMA_L2D/2_PRISMA_L2D_tif_2020_2023/\"\n",
    "forcing_path = \"/Volumes/ChenLab/Fujiang/0_PhD_dissertation_data/5_Forcing_data/3_clipped_forcing_WGS84/\"\n",
    "out_path = \"/Volumes/ChenLab/Fujiang/0_PhD_dissertation_data/5_Forcing_data/4_clipped_NEON_extent/\"\n",
    "\n",
    "variables = [\"dayl\",\"LAI\",\"prcp\",\"srad\",\"tmax\",\"tmin\",\"vp\"]\n",
    "site_list = ['D01_BART','D01_HARV','D02_SCBI','D03_OSBS','D07_MLBS','D07_ORNL','D08_TALL',\n",
    "             'D10_CPER','D13_MOAB','D14_JORN','D14_SRER','D16_WREF','D19_BONA','D19_HEAL']\n",
    "\n",
    "for site in site_list:\n",
    "    path = f\"{prisma_path}{site}\"\n",
    "    file_list = os.listdir(path)\n",
    "    file_list = [x for x in file_list if \"LATLON.tif\" in x]\n",
    "\n",
    "    ul_x_all,lr_y_all, lr_x_all, ul_y_all = [],[],[],[]\n",
    "    for file in file_list:\n",
    "        im_data, im_Geotrans, im_proj,rows, cols = read_tif(f\"{path}/{file}\")\n",
    "        ul_x, lr_y, lr_x, ul_y = im_data[0,0,1],im_data[-1,-1,0],im_data[-1,-1,1],im_data[0,0,0]\n",
    "        ul_x_all.append(ul_x)\n",
    "        lr_y_all.append(lr_y)\n",
    "        lr_x_all.append(lr_x)\n",
    "        ul_y_all.append(ul_y)\n",
    "    ul_x, lr_y, lr_x, ul_y = min(ul_x_all),min(lr_y_all), max(lr_x_all), max(ul_y_all)\n",
    "    ul_x, lr_y, lr_x, ul_y = ul_x-0.2, lr_y-0.2, lr_x+0.2, ul_y+0.2\n",
    "    print(site, ul_x, lr_y, lr_x, ul_y)\n",
    "    \n",
    "    for var in variables:\n",
    "        var_in_folder = f\"{forcing_path}{var}\"\n",
    "        var_out_folder = f\"{out_path}{var}\"\n",
    "        forcing_files = os.listdir(var_in_folder)\n",
    "        forcing_files = [x for x in forcing_files if \".tif\" in x and \".aux.xml\" not in x and \"._\" not in x]\n",
    "        os.makedirs(f\"{var_out_folder}/{site}\", exist_ok=True)\n",
    "        \n",
    "        for forcing_file in forcing_files:\n",
    "            input_tif = f\"{var_in_folder}/{forcing_file}\"\n",
    "            output_tif =f\"{var_out_folder}/{site}/{forcing_file}\"\n",
    "            gdal.Warp(output_tif, input_tif, format = 'GTiff', outputBounds=(ul_x, lr_y, lr_x, ul_y))\n",
    "            input_tif = None\n",
    "            output_tif = None\n",
    "            print(site,var,datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),forcing_file,\"finished\")\n",
    "            \n",
    "            ### transfer the projection of clipped land use data\n",
    "            in_tif = f\"{var_out_folder}/{site}/{forcing_file}\"\n",
    "            out_tif = f\"{var_out_folder}/{site}/{forcing_file}\"\n",
    "            input_ds = gdal.Open(in_tif)\n",
    "            output_ds = gdal.Warp(out_tif, input_ds, dstSRS=im_proj)\n",
    "            input_ds = None\n",
    "            output_ds = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
