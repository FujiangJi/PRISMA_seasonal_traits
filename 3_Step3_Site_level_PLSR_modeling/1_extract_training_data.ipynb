{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa3bfcdf-2b56-4c5f-8aac-814676de968f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T18:42:07.758218Z",
     "iopub.status.busy": "2024-08-15T18:42:07.757173Z",
     "iopub.status.idle": "2024-08-15T18:42:07.769044Z",
     "shell.execute_reply": "2024-08-15T18:42:07.767846Z",
     "shell.execute_reply.started": "2024-08-15T18:42:07.758137Z"
    }
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal, osr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import numpy as np\n",
    "import pyproj\n",
    "from shapely.wkt import loads\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import unary_union\n",
    "from shapely import speedups\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "import warnings\n",
    "from scipy.signal import find_peaks\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c729471a-eef6-4b2b-9b17-bfb4f7791350",
   "metadata": {},
   "source": [
    "## 1. Extract values to points for training dataset construction.\n",
    "- step 1: we got 10 paired NEON upscaled traits and PRISMA reflectance. the dates coincident within 0~12 days.\n",
    "- step 2: transfer the georeferenced NEON upscaled trait maps to points (in this case we use the vegetation fraction).\n",
    "- step 3: select the points that the vegetation fraction greater than 0.6\n",
    "- step 4: extract the land cover types to points.\n",
    "- step 5: extract 5 traits values to points and excluded those values lower than 0, as well as nan values.\n",
    "- step 6: extract PRISMA reflectance to points and exclude clouds and clouds shaded area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "073a5889-7d47-4b73-9caa-8d44256ba4c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T19:22:20.776955Z",
     "iopub.status.busy": "2024-04-02T19:22:20.776669Z",
     "iopub.status.idle": "2024-04-02T19:22:20.784253Z",
     "shell.execute_reply": "2024-04-02T19:22:20.782713Z",
     "shell.execute_reply.started": "2024-04-02T19:22:20.776939Z"
    }
   },
   "outputs": [],
   "source": [
    "def raster_to_points(geotiff, shp_name):\n",
    "    inDs = gdal.Open(geotiff)\n",
    "    DsoutDs = gdal.Translate(f\"{shp_name}.xyz\", inDs, format='XYZ', creationOptions=[\"ADD_HEADER_LINE=YES\"])\n",
    "    outDs = None\n",
    "    try:\n",
    "        os.remove(f'{shp_name}.csv')\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    os.rename(f'{shp_name}.xyz', f'{shp_name}.csv')\n",
    "    os.system('ogr2ogr -f \"ESRI Shapefile\" -oo X_POSSIBLE_NAMES=X* -oo Y_POSSIBLE_NAMES=Y* -oo KEEP_GEOM_COLUMNS=NO {0}.shp {0}.csv'.format(shp_name))\n",
    "    try:\n",
    "        os.remove(f'{shp_name}.csv')\n",
    "    except OSError:\n",
    "        pass\n",
    "    crs_wkt = inDs.GetProjection()\n",
    "    shp_layer = gpd.read_file(f\"{shp_name}.shp\")\n",
    "    shp_layer.crs = crs_wkt\n",
    "    shp_layer.to_file(f\"{shp_name}.shp\")\n",
    "    return\n",
    "\n",
    "land_cover_type = {10: \"Rainfed cropland\",11: \"Herbaceous cover cropland\",12: \"Tree or shrub cover (Orchard) cropland\",\n",
    "                   20: \"Irrigated cropland\",51: \"Open evergreen broadleaved forest\",52: \"Closed evergreen broadleaved forest\",\n",
    "                   61: \"Open deciduous broadleaved forest\",62: \"Closed deciduous broadleaved forest\",71: \"Open evergreen needle-leaved forest\",\n",
    "                   72: \"Closed evergreen needle-leaved forest\",81: \"Open deciduous needle-leaved forest\",82: \"Closed deciduous needle-leaved forest\",\n",
    "                   91: \"Open mixed leaf forest (broadleaved and needle-leaved)\",92: \"Closed mixed leaf forest (broadleaved and needle-leaved)\", \n",
    "                   120: \"Shrubland\",121: \"Evergreen shrubland\",122: \"Deciduous shrubland\",130: \"Grassland\",140: \"Lichens and mosses\",\n",
    "                   150: \"Sparse vegetation\",152: \"Sparse shrubland\",153: \"Sparse herbaceous\",181: \"Swamp\",182: \"Marsh\",183: \"Flooded flat\",\n",
    "                   184: \"Saline\",185: \"Mangrove\",186: \"Salt marsh\",187: \"Tidal flat\",190: \"Impervious surfaces\",200: \"Bare areas\",\n",
    "                   201: \"Consolidated bare areas\",202: \"Unconsolidated bare areas\",210: \"Water body\",220: \"Permanent ice and snow\",\n",
    "                   0: \"Filled value\",250: \"Filled value\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93697c1c-0b0b-4178-bd24-e9475bf42531",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T19:46:10.526594Z",
     "iopub.status.busy": "2024-04-02T19:46:10.526147Z",
     "iopub.status.idle": "2024-04-02T19:46:10.533930Z",
     "shell.execute_reply": "2024-04-02T19:46:10.532825Z",
     "shell.execute_reply.started": "2024-04-02T19:46:10.526570Z"
    }
   },
   "outputs": [],
   "source": [
    "flightname = [\"NEON_2020_D10_CPER_20200913\",\"NEON_2021_D10_CPER_20210525\",\"NEON_2021_D10_CPER_20210608\",\"NEON_2020_D13_MOAB_20200705\",\n",
    "              \"NEON_2021_D13_MOAB_20210429\",\"NEON_2021_D03_OSBS_20210924\",\"NEON_2021_D07_MLBS_20210617\",\"NEON_2021_D14_JORN_20210826\",\n",
    "              \"NEON_2021_D14_JORN_20210909\",\"NEON_2021_D16_WREF_20210724\"]\n",
    "\n",
    "## data path\n",
    "neon_data_path = \"/Volumes/UW_Madison/0_PhD_dissertation_data/1_NEON_AOP_trait_maps/4_upscaled_data/\"\n",
    "prisma_data_path = \"/Volumes/UW_Madison/0_PhD_dissertation_data/2_PRISMA_L2D/2_PRISMA_L2D_tif_2020_2023/\"\n",
    "landuse_path = \"/Volumes/UW_Madison/0_PhD_dissertation_data/3_GLC_FCS30D_Land_cover_data_US/4_land_cover_NEON_sites/\"\n",
    "out_path = \"/Volumes/UW_Madison/0_PhD_dissertation_data/4_Extract_training_data/1_original_extraction/\"\n",
    "\n",
    "## upscaled NEON trait maps folder\n",
    "neon_imagery = [f\"{neon_data_path}{x}\" for x in flightname]\n",
    "\n",
    "## PRISMA reflectance\n",
    "prisma_imagery = [f\"{prisma_data_path}D10_CPER/PRS_L2D_STD_20200914175311_20200914175315_0001_HCO_FULL\",\n",
    "                  f\"{prisma_data_path}D10_CPER/PRS_L2D_STD_20210527174644_20210527174649_0001_HCO_FULL\",\n",
    "                  f\"{prisma_data_path}D10_CPER/PRS_L2D_STD_20210614175648_20210614175652_0001_HCO_FULL\",\n",
    "                  f\"{prisma_data_path}D13_MOAB/PRS_L2D_STD_20200702181741_20200702181745_0001_HCO_FULL\",\n",
    "                  f\"{prisma_data_path}D13_MOAB/PRS_L2D_STD_20210511181051_20210511181056_0001_HCO_FULL\",\n",
    "                  f\"{prisma_data_path}D03_OSBS/PRS_L2D_STD_20210926161646_20210926161650_0001_HCO_FULL\",\n",
    "                  f\"{prisma_data_path}D07_MLBS/PRS_L2D_STD_20210608161711_20210608161716_0001_HCO_FULL\",\n",
    "                  f\"{prisma_data_path}D14_JORN/PRS_L2D_STD_20210817180252_20210817180257_0001_HCO_FULL\",\n",
    "                  f\"{prisma_data_path}D14_JORN/PRS_L2D_STD_20210909175942_20210909175946_0001_HCO_FULL\",\n",
    "                  f\"{prisma_data_path}D16_WREF/PRS_L2D_STD_20210729190927_20210729190932_0001_HCO_FULL\"]\n",
    "\n",
    "## output shapefiles stored extracted values of paired trait and reflectance\n",
    "shp_path = [f\"{out_path}{x}_extracted_points\" for x in flightname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9b6a73-6108-4bcb-ac38-cbba0fe7b13d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T19:56:56.428398Z",
     "iopub.status.busy": "2024-04-02T19:56:56.427975Z",
     "iopub.status.idle": "2024-04-02T21:20:09.401523Z",
     "shell.execute_reply": "2024-04-02T21:20:09.401222Z",
     "shell.execute_reply.started": "2024-04-02T19:56:56.428370Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(flightname)):\n",
    "    neon = neon_imagery[i]\n",
    "    flight = flightname[i]\n",
    "    prisma = prisma_imagery[i]\n",
    "    shp_name = shp_path[i]\n",
    "    year, site= flight.split(\"_\")[1], \"_\".join(flight.split(\"_\")[2:4])\n",
    "    \n",
    "    ## raster to points shapefile\n",
    "    geotiff = f\"{neon}/{flight}_vegetation_fraction_modified.tif\"\n",
    "    raster_to_points(geotiff, shp_name)\n",
    "    \n",
    "    points = gpd.read_file(f\"{shp_name}.shp\")\n",
    "    points[\"vege_frac\"] = points[\"Z\"].astype(float)\n",
    "    points = points[points[\"vege_frac\"]>0.5]\n",
    "    points.drop(columns=['Z'],inplace = True)\n",
    "    points.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    ## extract land use values to points\n",
    "    landuse_data = f\"{landuse_path}{site}/{site}_{year}_land_cover.tif\"\n",
    "    land_ds = gdal.Open(landuse_data)\n",
    "    \n",
    "    band = land_ds.GetRasterBand(1)\n",
    "    extracted_values = []\n",
    "    for index, row in points.iterrows():\n",
    "        point = row.geometry\n",
    "        x, y = point.x, point.y\n",
    "        # Convert point coordinates to pixel coordinates\n",
    "        px = int((x - land_ds.GetGeoTransform()[0]) / land_ds.GetGeoTransform()[1])\n",
    "        py = int((y - land_ds.GetGeoTransform()[3]) / land_ds.GetGeoTransform()[5])\n",
    "        # Read value from GeoTIFF\n",
    "        value = band.ReadAsArray(px, py, 1, 1)[0][0]\n",
    "        extracted_values.append(value)\n",
    "\n",
    "    extracted_values = [land_cover_type[x] for x in extracted_values]\n",
    "    points[\"LULC\"] = extracted_values\n",
    "\n",
    "    # extract trait values to points\n",
    "    tr_name = [\"Chlorophylls_area\",\"Carotenoids_area\",\"LMA\",\"EWT\",\"Nitrogen\"]\n",
    "    col_name = {\"Chlorophylls_area\":\"Chla+b\",\"Carotenoids_area\":\"Ccar\",\"LMA\":\"LMA\",\"EWT\":\"EWT\",\"Nitrogen\":\"Nitrogen\"}\n",
    "    for tr in tr_name:\n",
    "        in_tif = f\"{neon}/{flight}_{tr}_clipped_aggregated_modified.tif\"\n",
    "        tiff_ds = gdal.Open(in_tif)\n",
    "        \n",
    "        band = tiff_ds.GetRasterBand(1)\n",
    "        extracted_values = []\n",
    "        for index, row in points.iterrows():\n",
    "            point = row.geometry\n",
    "            x, y = point.x, point.y\n",
    "            # Convert point coordinates to pixel coordinates\n",
    "            px = int((x - tiff_ds.GetGeoTransform()[0]) / tiff_ds.GetGeoTransform()[1])\n",
    "            py = int((y - tiff_ds.GetGeoTransform()[3]) / tiff_ds.GetGeoTransform()[5])\n",
    "            # Read value from GeoTIFF\n",
    "            value = band.ReadAsArray(px, py, 1, 1)[0][0]\n",
    "            extracted_values.append(value)\n",
    "        points[col_name[tr]] = extracted_values\n",
    "    \n",
    "    points = points[(points[\"Chla+b\"]>0)&(points[\"Ccar\"]>0)&(points[\"EWT\"]>0)&(points[\"LMA\"]>0)&(points[\"Nitrogen\"]>0)]\n",
    "    points.dropna(inplace = True)\n",
    "    points.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    ## extract PRISMA reflectance values to points\n",
    "    in_tif = f\"{prisma}.tif\"\n",
    "    in_wl = f\"{prisma}.wvl\"\n",
    "    \n",
    "    tiff_ds = gdal.Open(in_tif)\n",
    "    # Get number of bands in GeoTIFF\n",
    "    num_bands = tiff_ds.RasterCount\n",
    "    \n",
    "    # Extract values for each point for each band\n",
    "    extracted_values = [[] for _ in range(num_bands)]\n",
    "    for index, row in points.iterrows():\n",
    "        point = row.geometry\n",
    "        x, y = point.x, point.y\n",
    "        \n",
    "        # Convert point coordinates to pixel coordinates\n",
    "        px = int((x - tiff_ds.GetGeoTransform()[0]) / tiff_ds.GetGeoTransform()[1])\n",
    "        py = int((y - tiff_ds.GetGeoTransform()[3]) / tiff_ds.GetGeoTransform()[5])\n",
    "        \n",
    "        # Read values from GeoTIFF for each band\n",
    "        for band_num in range(1, num_bands + 1):\n",
    "            band = tiff_ds.GetRasterBand(band_num)\n",
    "            value = band.ReadAsArray(px, py, 1, 1)[0][0]\n",
    "            extracted_values[band_num - 1].append(value)\n",
    "\n",
    "    df = pd.read_csv(in_wl,delimiter=\" \")\n",
    "    df['wl'] = round(df['wl'],2)\n",
    "    df['wl'] = df['wl'].astype(str)\n",
    "    wl = list(df['wl'])\n",
    "    extracted_values = pd.DataFrame(np.array(extracted_values)).T\n",
    "    extracted_values.columns = wl\n",
    "    points = pd.concat([points, extracted_values], axis = 1)\n",
    "    \n",
    "    points = points[points.iloc[:,8:28].mean(axis = 1)<0.15] ## exclude clouds (blue bands lower than 0.15)\n",
    "    points = points[points.iloc[:,63:83].mean(axis = 1)>0.2] ## exclude clouds shaded area (NIR bands greater than 0.2)\n",
    "\n",
    "    points.dropna(inplace = True)\n",
    "    points.reset_index(drop = True, inplace = True)\n",
    "    points.to_file(f\"{shp_name}.shp\")\n",
    "    print(i+1,\"Finished\", os.path.basename(neon))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73a0d675-3ca3-427e-b674-1c9e5972fd7d",
   "metadata": {},
   "source": [
    "## 2. Polish the extracted training data (QGIS).\n",
    "- look into details in QGIS softeware.\n",
    "- vegetation fraction greater than 0.6.\n",
    "- exclude the clouds and the shaded area.\n",
    "- exclude the points in the edge of NEON AOP flight lines.\n",
    "- exclude the points in the horizonal flight lines.\n",
    "- exclude the points in the land cover data that exhibited non-vegetation.\n",
    "- exclude neighboring points within a 100-meter radius to mitigate spatial autocorrelation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3adc6e42-799e-425a-9699-1d2ca7464bbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T21:28:32.385443Z",
     "iopub.status.busy": "2024-04-04T21:28:32.342022Z",
     "iopub.status.idle": "2024-04-04T21:28:32.637490Z",
     "shell.execute_reply": "2024-04-04T21:28:32.632553Z",
     "shell.execute_reply.started": "2024-04-04T21:28:32.384161Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_points(gdf, min_distance):\n",
    "    gdf_copy = gdf.copy()\n",
    "    to_remove = []\n",
    "\n",
    "    for index, row in gdf_copy.iterrows():\n",
    "        if index not in to_remove:\n",
    "            distances = gdf_copy.geometry.distance(row.geometry)\n",
    "            close_points = distances[distances < min_distance].index.tolist()\n",
    "            close_points.remove(index)\n",
    "            to_remove.extend(close_points)\n",
    "\n",
    "    gdf_copy.drop(index=to_remove, inplace=True)\n",
    "    gdf_copy.reset_index(drop = True, inplace = True)\n",
    "    return gdf_copy\n",
    "\n",
    "data_path = \"/Volumes/UW_Madison/0_PhD_dissertation_data/4_Extract_training_data/1_original_extraction/\"\n",
    "out_path = \"/Volumes/UW_Madison/0_PhD_dissertation_data/4_Extract_training_data/2_processing_extraction/\"\n",
    "\n",
    "file_name = os.listdir(data_path)\n",
    "file_name = [x for x in file_name if \".shp\" in x and \"._\" not in x]\n",
    "\n",
    "for file in file_name:\n",
    "    print(file)\n",
    "    points = gpd.read_file(f'{data_path}{file}')\n",
    "    filtered_points = filter_points(points, 100)\n",
    "    filtered_points.to_file(f'{out_path}{file}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac6a2b20-7369-4ea7-8684-2690d28fda09",
   "metadata": {},
   "source": [
    "## 3. Merge the polished data to one file.\n",
    "- add the necessary arttributes like the date, sites in the polished data.\n",
    "- merge the extracted points data of each sites to one file (*.csv format).\n",
    "- follow the Zhihui (https://doi.org/10.1111/nph.16711), Giulia (https://doi.org/10.1016/j.isprsjprs.2022.03.014) and Jochem's (https://doi.org/10.1016/j.isprsjprs.2021.06.017) paper to see how to prosess the extracted reflectance (smooth, vector normalization, exclude the water absorption bands, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f867b0be-06a4-4aa7-80c2-8f28065850f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T00:58:19.035465Z",
     "iopub.status.busy": "2024-04-05T00:58:19.032819Z",
     "iopub.status.idle": "2024-04-05T01:07:14.826334Z",
     "shell.execute_reply": "2024-04-05T01:07:14.822523Z",
     "shell.execute_reply.started": "2024-04-05T00:58:19.035407Z"
    }
   },
   "outputs": [],
   "source": [
    "## Add necessary arttributes to each shapfile and save as *.csv files\n",
    "\n",
    "shp_path = \"/Volumes/UW_Madison/0_PhD_dissertation_data/4_Extract_training_data/2_processing_extraction/\"\n",
    "out_path = \"/Volumes/UW_Madison/0_PhD_dissertation_data/4_Extract_training_data/3_save_to_csv/\"\n",
    "\n",
    "PRISMA_data = {'NEON_2020_D10_CPER_20200913_extracted_points.shp':\"20200914\",\n",
    "               'NEON_2020_D13_MOAB_20200705_extracted_points.shp':\"20200702\",\n",
    "               'NEON_2021_D03_OSBS_20210924_extracted_points.shp':\"20210926\",\n",
    "               'NEON_2021_D07_MLBS_20210617_extracted_points.shp':\"20210608\",\n",
    "               'NEON_2021_D13_MOAB_20210429_extracted_points.shp':\"20210511\",\n",
    "               'NEON_2021_D10_CPER_20210525_extracted_points.shp':\"20210527\",\n",
    "               'NEON_2021_D10_CPER_20210608_extracted_points.shp':\"20210614\",\n",
    "               'NEON_2021_D14_JORN_20210826_extracted_points.shp':\"20210817\",\n",
    "               'NEON_2021_D14_JORN_20210909_extracted_points.shp':\"20210909\",\n",
    "               'NEON_2021_D16_WREF_20210724_extracted_points.shp':\"20210729\"}\n",
    "\n",
    "file_name = os.listdir(shp_path)\n",
    "file_name = [x for x in file_name if \".shp\" in x and \"._\" not in x]\n",
    "for file in file_name:\n",
    "    print(file)\n",
    "    data = gpd.read_file(f\"{shp_path}{file}\")\n",
    "    data.insert(7,\"site\",file.split(\"_\")[3],allow_duplicates=False)\n",
    "    data.insert(8, \"NEON_date\", file.split(\"_\")[4], allow_duplicates=False)\n",
    "    data.insert(9, \"HYP_date\", PRISMA_data[file], allow_duplicates=False)\n",
    "    data.insert(10, \"X\", data['geometry'].x, allow_duplicates=False)\n",
    "    data.insert(11, \"Y\", data['geometry'].y, allow_duplicates=False)\n",
    "    data.insert(12, \"crs\", data.crs.name, allow_duplicates=False)\n",
    "    data.drop(columns = [\"geometry\"],inplace = True)\n",
    "    data.to_csv(f\"{out_path}{file[:-4]}.csv\",index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be13506d",
   "metadata": {},
   "source": [
    "## 4. Add the NBAR reflectance and LAI into training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f469d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_neon_prisma = {\"NEON_2020_D10_CPER_20200913_extracted_points.shp\":\"PRS_L2D_STD_20200914175311_20200914175315_0001_HCO_FULL\",\n",
    "                    \"NEON_2021_D10_CPER_20210525_extracted_points.shp\":\"PRS_L2D_STD_20210527174644_20210527174649_0001_HCO_FULL\",\n",
    "                    \"NEON_2021_D10_CPER_20210608_extracted_points.shp\":\"PRS_L2D_STD_20210614175648_20210614175652_0001_HCO_FULL\",\n",
    "                    \"NEON_2020_D13_MOAB_20200705_extracted_points.shp\":\"PRS_L2D_STD_20200702181741_20200702181745_0001_HCO_FULL\",\n",
    "                    \"NEON_2021_D13_MOAB_20210429_extracted_points.shp\":\"PRS_L2D_STD_20210511181051_20210511181056_0001_HCO_FULL\",\n",
    "                    \"NEON_2021_D03_OSBS_20210924_extracted_points.shp\":\"PRS_L2D_STD_20210926161646_20210926161650_0001_HCO_FULL\",\n",
    "                    \"NEON_2021_D07_MLBS_20210617_extracted_points.shp\":\"PRS_L2D_STD_20210608161711_20210608161716_0001_HCO_FULL\",\n",
    "                    \"NEON_2021_D14_JORN_20210826_extracted_points.shp\":\"PRS_L2D_STD_20210817180252_20210817180257_0001_HCO_FULL\",\n",
    "                    \"NEON_2021_D14_JORN_20210909_extracted_points.shp\":\"PRS_L2D_STD_20210909175942_20210909175946_0001_HCO_FULL\",\n",
    "                    \"NEON_2021_D16_WREF_20210724_extracted_points.shp\":\"PRS_L2D_STD_20210729190927_20210729190932_0001_HCO_FULL\"}\n",
    "\n",
    "data_path = \"/Volumes/ChenLab/Fujiang/0_Seasonal_PRISMA_traits/4_Extract_training_data/2_processing_extraction/NBAR_refl/\"\n",
    "neon_data_path = \"/Volumes/ChenLab/Fujiang/0_Seasonal_PRISMA_traits/1_NEON_AOP_trait_maps/4_upscaled_data/\"\n",
    "prisma_data_path = \"/Volumes/ChenLab/Fujiang/0_Seasonal_PRISMA_traits/2_PRISMA_L2D/3_PRISMA_full_band_data/6_BRDF_correction/\"\n",
    "wvl_path = \"/Volumes/ChenLab/Fujiang/0_Seasonal_PRISMA_traits/2_PRISMA_L2D/4_PRISMA_wvl_data/\"\n",
    "\n",
    "file_name = os.listdir(data_path)\n",
    "file_name = [x for x in file_name if \".shp\" in x and \"._\" not in x]\n",
    "\n",
    "for file in file_name:\n",
    "    points = gpd.read_file(f'{data_path}{file}')\n",
    "    \n",
    "    site = (\"_\").join(file.split(\"_\")[2:4])\n",
    "    imagery_path = f\"{prisma_data_path}{site}\"\n",
    "    wvl_folder = f\"{wvl_path}{site}\"\n",
    "    prisma = pair_neon_prisma[file]\n",
    "\n",
    "    in_tif = f\"{imagery_path}/{prisma}_NBAR.tif\"\n",
    "    in_wl = f\"{wvl_folder}/{prisma}.wvl\"\n",
    "    tiff_ds = gdal.Open(in_tif)\n",
    "   \n",
    "    num_bands = tiff_ds.RasterCount\n",
    "    \n",
    "    extracted_values = [[] for _ in range(num_bands)]\n",
    "    for index, row in points.iterrows():\n",
    "        point = row.geometry\n",
    "        x, y = point.x, point.y\n",
    "        \n",
    "        # Convert point coordinates to pixel coordinates\n",
    "        px = int((x - tiff_ds.GetGeoTransform()[0]) / tiff_ds.GetGeoTransform()[1])\n",
    "        py = int((y - tiff_ds.GetGeoTransform()[3]) / tiff_ds.GetGeoTransform()[5])\n",
    "        \n",
    "        # Read values from GeoTIFF for each band\n",
    "        for band_num in range(1, num_bands + 1):\n",
    "            band = tiff_ds.GetRasterBand(band_num)\n",
    "            value = band.ReadAsArray(px, py, 1, 1)[0][0]\n",
    "            extracted_values[band_num - 1].append(value)\n",
    "\n",
    "    df = pd.read_csv(in_wl,delimiter=\" \")\n",
    "    df['wl'] = round(df['wl'],2)\n",
    "    df['wl'] = df['wl'].astype(str)\n",
    "    wl = list(df['wl'])\n",
    "    extracted_values = pd.DataFrame(np.array(extracted_values)).T\n",
    "    extracted_values.columns = wl\n",
    "    for col in extracted_values.columns:\n",
    "        points[col] = extracted_values[col]\n",
    "    points.to_file(f'{data_path}{file}')\n",
    "    print(\"Finished:\", file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde9379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Volumes/ChenLab-1/Fujiang/0_Seasonal_PRISMA_traits/4_Extract_training_data/2_processing_extraction/NBAR_refl/\"\n",
    "LAI_path = \"/Volumes/ChenLab-1/Fujiang/0_Seasonal_PRISMA_traits/12_RTM_estimation_through_given_LAI/1_LAI_estimation/8_estimated_LAI_VI_masked/NBAR_refl/\"\n",
    "\n",
    "file_name = os.listdir(data_path)\n",
    "file_name = [x for x in file_name if \".shp\" in x and \"._\" not in x]\n",
    "\n",
    "for file in file_name:\n",
    "    points = gpd.read_file(f'{data_path}{file}')\n",
    "    site = (\"_\").join(file.split(\"_\")[2:4])\n",
    "    lai_path = f\"{LAI_path}{site}\"\n",
    "    prisma = pair_neon_prisma[file]\n",
    "    \n",
    "    in_tif = f\"{lai_path}/{prisma}_NBAR_LAI_VI_masked.tif\"\n",
    "    tiff_ds = gdal.Open(in_tif)\n",
    "    num_bands = tiff_ds.RasterCount\n",
    "        \n",
    "    extracted_values = [[] for _ in range(num_bands)]\n",
    "    for index, row in points.iterrows():\n",
    "        point = row.geometry\n",
    "        x, y = point.x, point.y\n",
    "        \n",
    "        # Convert point coordinates to pixel coordinates\n",
    "        px = int((x - tiff_ds.GetGeoTransform()[0]) / tiff_ds.GetGeoTransform()[1])\n",
    "        py = int((y - tiff_ds.GetGeoTransform()[3]) / tiff_ds.GetGeoTransform()[5])\n",
    "        \n",
    "        # Read values from GeoTIFF for each band\n",
    "        for band_num in range(1, num_bands + 1):\n",
    "            band = tiff_ds.GetRasterBand(band_num)\n",
    "            value = band.ReadAsArray(px, py, 1, 1)[0][0]\n",
    "            extracted_values[band_num - 1].append(value)\n",
    "    extracted_values = pd.DataFrame(np.array(extracted_values)).T\n",
    "    extracted_values.columns = [\"NDVI\",\"NIRv\",\"LAI\"]\n",
    "    points = pd.concat([points, extracted_values], axis = 1)\n",
    "    points.to_file(f'{data_path}{file[:-4]}_add_LAI.shp')\n",
    "    print(\"Finished:\", file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cb3870",
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_path = \"/Volumes/ChenLab-1/Fujiang/0_Seasonal_PRISMA_traits/4_Extract_training_data/2_processing_extraction/NBAR_refl/\"\n",
    "out_path = \"/Volumes/ChenLab-1/Fujiang/0_Seasonal_PRISMA_traits/4_Extract_training_data/3_save_to_csv/NBAR_refl/\"\n",
    "\n",
    "PRISMA_data = {'NEON_2020_D10_CPER_20200913_extracted_points_add_LAI.shp':\"20200914\",\n",
    "               'NEON_2020_D13_MOAB_20200705_extracted_points_add_LAI.shp':\"20200702\",\n",
    "               'NEON_2021_D03_OSBS_20210924_extracted_points_add_LAI.shp':\"20210926\",\n",
    "               'NEON_2021_D07_MLBS_20210617_extracted_points_add_LAI.shp':\"20210608\",\n",
    "               'NEON_2021_D13_MOAB_20210429_extracted_points_add_LAI.shp':\"20210511\",\n",
    "               'NEON_2021_D10_CPER_20210525_extracted_points_add_LAI.shp':\"20210527\",\n",
    "               'NEON_2021_D10_CPER_20210608_extracted_points_add_LAI.shp':\"20210614\",\n",
    "               'NEON_2021_D14_JORN_20210826_extracted_points_add_LAI.shp':\"20210817\",\n",
    "               'NEON_2021_D14_JORN_20210909_extracted_points_add_LAI.shp':\"20210909\",\n",
    "               'NEON_2021_D16_WREF_20210724_extracted_points_add_LAI.shp':\"20210729\"}\n",
    "\n",
    "file_name = os.listdir(shp_path)\n",
    "file_name = [x for x in file_name if \"_add_LAI.shp\" in x and \"._\" not in x]\n",
    "for file in file_name:\n",
    "    print(file)\n",
    "    data = gpd.read_file(f\"{shp_path}{file}\")\n",
    "    data.insert(7,\"site\",file.split(\"_\")[3],allow_duplicates=False)\n",
    "    data.insert(8, \"NEON_date\", file.split(\"_\")[4], allow_duplicates=False)\n",
    "    data.insert(9, \"HYP_date\", PRISMA_data[file], allow_duplicates=False)\n",
    "    data.insert(10, \"X\", data['geometry'].x, allow_duplicates=False)\n",
    "    data.insert(11, \"Y\", data['geometry'].y, allow_duplicates=False)\n",
    "    data.insert(12, \"crs\", data.crs.name, allow_duplicates=False)\n",
    "    data.drop(columns = [\"geometry\"],inplace = True)\n",
    "    data.to_csv(f\"{out_path}{file[:-4]}.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4769b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"/Volumes/ChenLab-1/Fujiang/0_Seasonal_PRISMA_traits/4_Extract_training_data/3_save_to_csv/NBAR_refl/\"\n",
    "out_path = \"/Volumes/ChenLab-1/Fujiang/0_Seasonal_PRISMA_traits/4_Extract_training_data/5_merged_csv_data/\"\n",
    "file_name = os.listdir(csv_path)\n",
    "file_name = [x for x in file_name if (\"_add_LAI.csv\" in x)&(\"._\" not in x)]\n",
    "\n",
    "var_start = True\n",
    "for file in file_name:\n",
    "    df = pd.read_csv(f\"{csv_path}{file}\")\n",
    "    if var_start:\n",
    "        results = df\n",
    "        var_start = False\n",
    "    else:\n",
    "        results = pd.concat([results, df],axis = 0)\n",
    "\n",
    "PFTs = {'Shrubland':\"SHR\", 'Open evergreen needle-leaved forest':\"ENF\", 'Lichens and mosses':np.nan,\n",
    "        'Open mixed leaf forest (broadleaved and needle-leaved)':\"MF\",'Grassland': \"GRA\", 'Herbaceous cover cropland': \"CPR\",\n",
    "        'Open deciduous broadleaved forest':\"DBF\", 'Closed evergreen needle-leaved forest':\"ENF\", 'Rainfed cropland':\"CPR\",\n",
    "        'Open deciduous needle-leaved forest':\"DNF\", 'Irrigated cropland':\"CPR\",'Closed evergreen broadleaved forest':\"EBF\",\n",
    "        'Closed deciduous broadleaved forest':\"DBF\", 'Sparse vegetation':np.nan,'Open evergreen broadleaved forest':\"EBF\",\n",
    "        'Closed deciduous needle-leaved forest':\"DNF\", 'Impervious surfaces':np.nan}\n",
    "pfts = [PFTs[x] for x in results[\"LULC\"]]\n",
    "results[\"PFT\"] = pfts\n",
    "results.dropna(subset=['PFT'],inplace = True)\n",
    "results[\"Nitrogen\"]= (results[\"Nitrogen\"]* results[\"LMA\"])/1000\n",
    "\n",
    "results.dropna(subset=['LAI'], inplace = True)\n",
    "results.reset_index(drop = True, inplace = True)\n",
    "results.to_csv(f\"{out_path}2020 and 2021 NEON extracted leaf traits and spectra data_NBAR_add_LAI.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
